{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 128 # number of transducer elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reproduce ABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antirectifier(x):   #copy from https://www.tensorflow.org/.../keras/layers/Lambda\n",
    "    x -= K.mean(x, axis=1, keepdims=True)\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    pos = K.relu(x)\n",
    "    neg = K.relu(-x)\n",
    "    return K.concatenate([pos, neg], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = keras.Input(shape=(Ne,))\n",
    "x = keras.layers.Dense(Ne)(_input)\n",
    "x = keras.layers.Lambda(antirectifier)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x = keras.layers.Dense(Ne/4)(x)\n",
    "x = keras.layers.Lambda(antirectifier)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "x = keras.layers.Dense(Ne/4)(x)\n",
    "x = keras.layers.Lambda(antirectifier)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "weights = keras.layers.Dense(Ne, name = \"weights\")(x)  # no activation is applied\n",
    "sumWeights = keras.layers.Lambda(lambda x: K.sum(x, axis=1, keepdims=True), name = \"sumWeights\")(weights) \n",
    "\n",
    "multiplied = keras.layers.Multiply()([_input, weights])\n",
    "output = keras.layers.Lambda(lambda x: K.sum(x, axis=1, keepdims=True), name=\"output\")(multiplied)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[_input],\n",
    "    outputs=[output,sumWeights],\n",
    ")\n",
    "\n",
    "#uncomment to see the architecture of the model\n",
    "#keras.utils.plot_model(model, \"ABLE_model_with_shape_info.png\", show_shapes=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 Define loss functions and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_SMSLE(y_true, y_pred, scale=1.):\n",
    "    first_log = K.log(K.clip(K.abs(y_pred[:, :1]) * scale, K.epsilon(), None) + 1.) * K.sign(y_pred[:, :1])\n",
    "    second_log = K.log(K.clip(K.abs(y_true[:, :1]) * scale, K.epsilon(), None) + 1.) * K.sign(y_true[:, :1])\n",
    "    return K.mean(K.square(first_log - second_log), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_unity(y_true, y_pred):\n",
    "    return K.mean( K.square(y_pred - y_true),  axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss={\"output\":loss_SMSLE, \"sumWeights\":loss_unity},\n",
    "    loss_weights=[1,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. Prepare x_train / y_train / y_train_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFilepath = r'E:\\Desktop\\internshipDeepUS\\04_16_2021_(ABLE)\\Input_Target_ABLE\\input\\PICMUS16.mat'\n",
    "targetFilepath = r'E:\\Desktop\\internshipDeepUS\\04_16_2021_(ABLE)\\Input_Target_ABLE\\target\\PICMUS16.mat'\n",
    "datasetsNames = ['carotid_cross','carotid_long','contrast_expe','resolution_expe','contrast_simu','resolution_simu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = scio.loadmat(inputFilepath)\n",
    "targetFile = scio.loadmat(targetFilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape of each dataset: (235683, 128)\n",
      "target shape of each dataset: (235683, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"input shape of each dataset:\",inputFile[datasetsNames[1]].shape)\n",
    "print(\"target shape of each dataset:\",targetFile[datasetsNames[1]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([inputFile[datasetsNames[i]] for i in range(len(datasetsNames))],axis=0) # x_train.shape=(1414098, 128)\n",
    "y_train = np.concatenate([targetFile[datasetsNames[i]] for i in range(len(datasetsNames))],axis=0)# y_train.shape=(1414098, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weights = np.ones([1414098,1]) # y_train_weights.shape=(1414098, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.3\n",
    "EPOCHS = 10\n",
    "checkpoint_filepath = '../tmp/checkpoint'\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stop_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30934/30934 [==============================] - 201s 6ms/step - loss: 1.7578 - output_loss: 1.7523 - sumWeights_loss: 0.0055 - val_loss: 1.5884 - val_output_loss: 1.5884 - val_sumWeights_loss: 3.2311e-05\n",
      "Epoch 2/10\n",
      "30934/30934 [==============================] - 193s 6ms/step - loss: 0.9766 - output_loss: 0.9738 - sumWeights_loss: 0.0028 - val_loss: 1.6664 - val_output_loss: 1.6652 - val_sumWeights_loss: 0.0012\n",
      "Epoch 3/10\n",
      "30934/30934 [==============================] - 186s 6ms/step - loss: 0.8266 - output_loss: 0.8237 - sumWeights_loss: 0.0029 - val_loss: 1.7267 - val_output_loss: 1.7264 - val_sumWeights_loss: 2.4857e-04\n",
      "Epoch 4/10\n",
      "30934/30934 [==============================] - 188s 6ms/step - loss: 0.7517 - output_loss: 0.7487 - sumWeights_loss: 0.0030 - val_loss: 1.7866 - val_output_loss: 1.7733 - val_sumWeights_loss: 0.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e6f106be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case, The model.compile()'s argument \"loss_weights=[1,1]\", which is equal to lambda = 0.5 \n",
    "# (lambda is the weight ratio  who is defined in ABLE paper)\n",
    "\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen so far.\n",
    "model.fit(x=x_train, y=[y_train, y_train_weights], \n",
    "          validation_split=val_split, epochs=EPOCHS, \n",
    "          callbacks=[model_checkpoint_callback,early_stop_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_model.tf\")\n",
    "# model.save_weights(\"my_weights.tf\")\n",
    "\n",
    "# If set \"loss_weights=[1,50]\"\n",
    "\n",
    "# model.fit(\n",
    "#     x=x_train, y=[y_train, y_train_weights], batch_size=None, epochs=4, verbose=1\n",
    "# )\n",
    "\n",
    "# Epoch 1/4\n",
    "# 44191/44191 [==============================] - 247s 5ms/step - loss: 2.5075 - output_loss: 2.3395 - sumWeights_loss: 0.0034\n",
    "# Epoch 2/4\n",
    "# 44191/44191 [==============================] - 245s 6ms/step - loss: 2.2096 - output_loss: 2.0750 - sumWeights_loss: 0.0027\n",
    "# Epoch 3/4\n",
    "# 44191/44191 [==============================] - 227s 5ms/step - loss: 2.0816 - output_loss: 1.9278 - sumWeights_loss: 0.0031\n",
    "# Epoch 4/4\n",
    "# 44191/44191 [==============================] - 229s 5ms/step - loss: 1.9868 - output_loss: 1.8230 - sumWeights_loss: 0.0033"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
